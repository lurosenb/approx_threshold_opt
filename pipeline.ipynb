{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "import gc\n",
    "\n",
    "from approx_thresh_general import tpr, fpr, precision\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from pipeline import FairDataset, FairPipeline, accuracy, f1\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "my_classifiers = {\n",
    "    # 'logistic_regression': LogisticRegression(),\n",
    "    # 'random_forest': RandomForestClassifier(),\n",
    "    # 'gradient_boosting': GradientBoostingClassifier(),\n",
    "    # 'svc': SVC(probability=True),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    # 'mlp': MLPClassifier()\n",
    "}\n",
    "\n",
    "metrics_dict = {\n",
    "    'tpr': tpr,\n",
    "    'fpr': fpr,\n",
    "    'precision': precision,\n",
    "    'accuracy': accuracy,\n",
    "    'f1': f1\n",
    "}\n",
    "\n",
    "metrics_functions = {\n",
    "    'tpr': tpr,\n",
    "    'fpr': fpr,\n",
    "    'precision': precision,\n",
    "}\n",
    "\n",
    "pipeline = FairPipeline(classifiers=my_classifiers, \n",
    "                        classifier_config_path='configs/classifier_config.yml', \n",
    "                        metrics=metrics_dict,\n",
    "                        metric_functions=metrics_functions,\n",
    "                        lambda_=0.8)\n",
    "\n",
    "X = pd.read_csv(f'matrices/ACSEmployment/Xs.csv')\n",
    "y = pd.read_csv(f'matrices/ACSEmployment/ys.csv').squeeze()\n",
    "\n",
    "acs_dataset = FairDataset(X, y, 'RAC1P_recoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the full pipeline...\n",
      "Running pipeline for dataset: ACSEmployment\n",
      "Overall metrics for knn (original): {'tpr': 0.8596976793698106, 'fpr': 0.2247670807453416, 'precision': 0.7771362586605081, 'accuracy': 0.8155142654076556, 'f1': 0.8163347821692105}\n",
      "Hyperparameters: {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "Metrics for knn (original) on 1: {'tpr': 0.8596648713345302, 'fpr': 0.2158899494665918, 'precision': 0.7888522789676002, 'accuracy': 0.820683661645423, 'f1': 0.822737686139748}\n",
      "Hyperparameters: {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "Metrics for knn (original) on 2: {'tpr': 0.8485401459854015, 'fpr': 0.23529411764705882, 'precision': 0.7536466774716369, 'accuracy': 0.8031825795644891, 'f1': 0.7982832618025751}\n",
      "Hyperparameters: {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "Metrics for knn (original) on 3: {'tpr': 0.8624708624708625, 'fpr': 0.28054298642533937, 'precision': 0.7489878542510121, 'accuracy': 0.7898966704936854, 'f1': 0.8017334777898159}\n",
      "Hyperparameters: {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "Metrics for knn (original) on 4: {'tpr': 0.873015873015873, 'fpr': 0.2250996015936255, 'precision': 0.744920993227991, 'accuracy': 0.8170454545454545, 'f1': 0.8038976857490865}\n",
      "Hyperparameters: {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "Adjusted max_error to 0.04440206577687346 to limit total combinations to approximately 1000\n",
      "Number of points in the epsilon net: 7\n",
      "Adjusted max_error: 0.04440206577687346\n",
      "Number of points in data: 9849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Threshold Combinations: 100%|██████████| 2401/2401 [00:10<00:00, 235.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best objective value: 0.584964341625366\n",
      "Best thresholds: {1: 0.3333333333333333, 2: 0.3333333333333333, 3: 0.3333333333333333, 4: 0.3333333333333333}\n",
      "Overall metrics for knn (fair): {'tpr': 0.9584841388120077, 'fpr': 0.31288819875776397, 'precision': 0.7363428197579326, 'accuracy': 0.8165295969133922, 'f1': 0.8328554250300619}\n",
      "Hyperparameters: {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "Metrics for knn (fair) on 1: {'tpr': 0.9539198084979055, 'fpr': 0.3074115665356541, 'precision': 0.7443380807844968, 'accuracy': 0.819090382387022, 'f1': 0.8361967213114754}\n",
      "Hyperparameters: {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "Metrics for knn (fair) on 2: {'tpr': 0.9635036496350365, 'fpr': 0.3219814241486068, 'precision': 0.717391304347826, 'accuracy': 0.8090452261306532, 'f1': 0.822429906542056}\n",
      "Hyperparameters: {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "Metrics for knn (fair) on 3: {'tpr': 0.9766899766899767, 'fpr': 0.3416289592760181, 'precision': 0.7350877192982456, 'accuracy': 0.8151549942594719, 'f1': 0.8388388388388388}\n",
      "Hyperparameters: {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "Metrics for knn (fair) on 4: {'tpr': 0.9708994708994709, 'fpr': 0.3147410358565737, 'precision': 0.699047619047619, 'accuracy': 0.8079545454545455, 'f1': 0.8128460686600222}\n",
      "Hyperparameters: {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "Overall metrics for knn (original): {'tpr': 0.8596976793698106, 'fpr': 0.2247670807453416, 'precision': 0.7771362586605081, 'accuracy': 0.8155142654076556, 'f1': 0.8163347821692105}\n",
      "Hyperparameters: {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "Metrics for knn (original) on 1.0: {'tpr': 0.864853195164076, 'fpr': 0.1913527397260274, 'precision': 0.8175510204081633, 'accuracy': 0.8366294067067928, 'f1': 0.8405371380612673}\n",
      "Hyperparameters: {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "Metrics for knn (original) on 2.0: {'tpr': 0.8546829063418732, 'fpr': 0.25248579545454547, 'precision': 0.7410779315367808, 'accuracy': 0.7966134308254762, 'f1': 0.7938365515896235}\n",
      "Hyperparameters: {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "Adjusted max_error to 0.009673893960624732 to limit total combinations to approximately 1000\n",
      "Number of points in the epsilon net: 33\n",
      "Adjusted max_error: 0.009673893960624732\n",
      "Number of points in data: 9849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Threshold Combinations: 100%|██████████| 1089/1089 [00:05<00:00, 195.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best objective value: 0.2220494342777255\n",
      "Best thresholds: {1.0: 0.625, 2.0: 0.625}\n",
      "Overall metrics for knn (fair): {'tpr': 0.6961890568447946, 'fpr': 0.07317546583850931, 'precision': 0.8966273649574993, 'accuracy': 0.8168341963651132, 'f1': 0.783796740172579}\n",
      "Hyperparameters: {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "Metrics for knn (fair) on 1.0: {'tpr': 0.7072538860103627, 'fpr': 0.06806506849315068, 'precision': 0.9115191986644408, 'accuracy': 0.8200773860705073, 'f1': 0.7964989059080962}\n",
      "Hyperparameters: {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "Metrics for knn (fair) on 2.0: {'tpr': 0.6854262914741706, 'fpr': 0.07741477272727272, 'precision': 0.8821621621621621, 'accuracy': 0.813931114104291, 'f1': 0.7714488300638147}\n",
      "Hyperparameters: {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "Running pipeline for dataset: students\n",
      "Overall metrics for knn (original): {'tpr': 0.8608695652173913, 'fpr': 0.011056511056511056, 'precision': 0.9565217391304348, 'accuracy': 0.960727969348659, 'f1': 0.9061784897025171}\n",
      "Hyperparameters: {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Metrics for knn (original) on 0: {'tpr': 0.8571428571428571, 'fpr': 0.005747126436781609, 'precision': 0.9782608695652174, 'accuracy': 0.9624724061810155, 'f1': 0.9137055837563451}\n",
      "Hyperparameters: {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Metrics for knn (original) on 1: {'tpr': 0.864, 'fpr': 0.015021459227467811, 'precision': 0.9391304347826087, 'accuracy': 0.9593908629441624, 'f1': 0.9}\n",
      "Hyperparameters: {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Adjusted max_error to 0.011610369082251095 to limit total combinations to approximately 1000\n",
      "Number of points in the epsilon net: 33\n",
      "Adjusted max_error: 0.011610369082251095\n",
      "Number of points in data: 1044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Threshold Combinations: 100%|██████████| 1089/1089 [00:05<00:00, 201.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best objective value: 0.11300744210026964\n",
      "Best thresholds: {0: 0.40625, 1: 0.40625}\n",
      "Overall metrics for knn (fair): {'tpr': 0.8608695652173913, 'fpr': 0.011056511056511056, 'precision': 0.9565217391304348, 'accuracy': 0.960727969348659, 'f1': 0.9061784897025171}\n",
      "Hyperparameters: {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Metrics for knn (fair) on 0: {'tpr': 0.8571428571428571, 'fpr': 0.005747126436781609, 'precision': 0.9782608695652174, 'accuracy': 0.9624724061810155, 'f1': 0.9137055837563451}\n",
      "Hyperparameters: {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Metrics for knn (fair) on 1: {'tpr': 0.864, 'fpr': 0.015021459227467811, 'precision': 0.9391304347826087, 'accuracy': 0.9593908629441624, 'f1': 0.9}\n",
      "Hyperparameters: {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Pipeline run completed.\n"
     ]
    }
   ],
   "source": [
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "CONFIG_PATH = 'configs/test_config.yml'\n",
    "\n",
    "config = load_config(CONFIG_PATH)\n",
    "datasets = config['datasets']\n",
    "classifier_config_path = 'configs/classifier_config.yml'\n",
    "\n",
    "# set to True to estimate runtime\n",
    "ESTIMATE_RUNTIME = False\n",
    "\n",
    "# here we estimate the runtime for the pipeline\n",
    "if ESTIMATE_RUNTIME:\n",
    "    total_runtime = 0\n",
    "    for dataset_name, sensitive_attrs in datasets.items():\n",
    "        print(f\"Estimating runtime for dataset: {dataset_name}\")\n",
    "        if dataset_name in ('ACSEmployment','ACSIncome','ACSMobility','ACSPublicCoverage','ACSTravelTime'):\n",
    "            X = pd.read_csv(f'matrices/{dataset_name}/Xs.csv')\n",
    "            y = pd.read_csv(f'matrices/{dataset_name}/ys.csv').squeeze()\n",
    "        else:\n",
    "            X = pd.read_csv(f'matrices/{dataset_name}/X.csv')\n",
    "            y = pd.read_csv(f'matrices/{dataset_name}/y.csv').squeeze()\n",
    "\n",
    "        # remove any rows that have null or nan\n",
    "        X.dropna(inplace=True)\n",
    "        y = y[X.index]\n",
    "\n",
    "        dataset = FairDataset(X, y, sensitive_attrs)\n",
    "\n",
    "        for sensitive_attr in sensitive_attrs:\n",
    "            pipeline = FairPipeline(classifiers=my_classifiers, \n",
    "                                    classifier_config_path=classifier_config_path, \n",
    "                                    metrics=metrics_dict,\n",
    "                                    metric_functions=metrics_functions,\n",
    "                                    lambda_=0.8, max_error=0.01, max_total_combinations=1000)\n",
    "\n",
    "            runtime = pipeline.estimate_runtime(dataset, sensitive_attr)\n",
    "            total_runtime += runtime\n",
    "\n",
    "        del X, y, dataset\n",
    "        gc.collect()\n",
    "        print()\n",
    "\n",
    "    print(f\"Total estimated runtime for all datasets and sensitive attributes: {total_runtime:.2f} seconds\")\n",
    "\n",
    "proceed = input(\"Do you want to proceed with the full pipeline run? (yes/no): \").strip().lower()\n",
    "\n",
    "if proceed == 'yes':\n",
    "    print(\"Running the full pipeline...\")\n",
    "    all_results = pd.DataFrame()\n",
    "    for dataset_name, sensitive_attrs in datasets.items():\n",
    "        print(f\"Running pipeline for dataset: {dataset_name}\")\n",
    "        if dataset_name in ('ACSEmployment','ACSIncome','ACSMobility','ACSPublicCoverage','ACSTravelTime'):\n",
    "            X = pd.read_csv(f'matrices/{dataset_name}/Xs.csv')\n",
    "            y = pd.read_csv(f'matrices/{dataset_name}/ys.csv').squeeze()\n",
    "        else:\n",
    "            X = pd.read_csv(f'matrices/{dataset_name}/X.csv')\n",
    "            y = pd.read_csv(f'matrices/{dataset_name}/y.csv').squeeze()\n",
    "\n",
    "        # remove any rows that have null or nan\n",
    "        X.dropna(inplace=True)\n",
    "        y = y[X.index]\n",
    "\n",
    "        dataset = FairDataset(X, y, sensitive_attrs)\n",
    "\n",
    "        for sensitive_attr in sensitive_attrs:\n",
    "            pipeline = FairPipeline(classifiers=my_classifiers, \n",
    "                                    classifier_config_path=classifier_config_path, \n",
    "                                    metrics=metrics_dict,\n",
    "                                    metric_functions=metrics_functions,\n",
    "                                    lambda_=0.8, max_error=0.01, max_total_combinations=1000)\n",
    "\n",
    "            pipeline.tune_and_evaluate(dataset, dataset_name, sensitive_attr)\n",
    "            results = pipeline.results_df\n",
    "            results['sensitive_attr'] = sensitive_attr\n",
    "            results['dataset'] = dataset_name\n",
    "            all_results = all_results.append(results, ignore_index=True)\n",
    "            \n",
    "        # this avoids memory issues\n",
    "        del X, y, dataset\n",
    "        gc.collect()\n",
    "\n",
    "    print(\"Pipeline run completed.\")\n",
    "else:\n",
    "    print(\"Pipeline run aborted.\")\n",
    "\n",
    "# dump all results to pickle dataframe\n",
    "all_results.to_pickle('all_results.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
