{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import yaml\n",
    "import argparse\n",
    "import gc\n",
    "\n",
    "from metrics import tpr, fpr, precision, npv, accuracy, f1, selection_rate\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from pipeline import FairDataset, FairPipeline, tpr_score, fpr_score, npv_score, selection_rate_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "my_classifiers = {\n",
    "    # 'lgb': lgb.LGBMClassifier(verbose=-1)\n",
    "    'xgb': xgb.XGBClassifier()\n",
    "    # 'logistic_regression': LogisticRegression(),\n",
    "    # 'random_forest': RandomForestClassifier(),\n",
    "    # 'gradient_boosting': GradientBoostingClassifier(),\n",
    "    # 'svc': SVC(probability=True),\n",
    "    # 'knn': KNeighborsClassifier(),\n",
    "    # 'mlp': MLPClassifier()\n",
    "    # decision tree\n",
    "}\n",
    "\n",
    "# These are the metrics included in the results dict\n",
    "metrics_dict = {\n",
    "    'tpr': tpr_score,\n",
    "    'fpr': fpr_score,\n",
    "    'precision': precision_score,\n",
    "    'npv': npv_score,\n",
    "    'accuracy': accuracy_score,\n",
    "    'f1': f1_score,\n",
    "    'selection_rate': selection_rate_score\n",
    "}\n",
    "\n",
    "# This is what we are equalizing in the objective\n",
    "metrics_functions = {\n",
    "    'tpr': tpr,\n",
    "    'fpr': fpr,\n",
    "    'precision': precision,\n",
    "    'npv': npv,\n",
    "    'selection_rate': selection_rate\n",
    "}\n",
    "\n",
    "global_metrics_map = {\n",
    "    'f1': f1,\n",
    "    'precision': precision,\n",
    "    'npv': npv,\n",
    "    'accuracy': accuracy,\n",
    "}\n",
    "\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "#parser = argparse.ArgumentParser(description='Run the pipeline for a specific dataset and with a custom output file name.')\n",
    "#parser.add_argument('--dataset_name', type=str, help='Name of the dataset to run the pipeline for', required=True)\n",
    "#parser.add_argument('--output_file', type=str, help='Name for the output .pkl file', required=True)\n",
    "\n",
    "#args = parser.parse_args()\n",
    "\n",
    "CONFIG_PATH = 'configs/exp01_num_of_groups.yml'\n",
    "\n",
    "config = load_config(CONFIG_PATH)\n",
    "datasets = config['datasets']\n",
    "dataset_names = list(datasets.keys())\n",
    "datasets_settings = config['datasets_settings']\n",
    "lambda_settings = config['lambda_settings']\n",
    "\n",
    "classifier_config_path = 'configs/test_classifier_config.yml'\n",
    "\n",
    "#DATASET_NAME = args.dataset_name\n",
    "OUTPUT_FILE = 'exp01_results.pkl'\n",
    "\n",
    "#print(DATASET_NAME)\n",
    "#print(OUTPUT_FILE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# set to True to estimate runtime\n",
    "ESTIMATE_RUNTIME = False\n",
    "\n",
    "  \n",
    "all_results = pd.DataFrame()\n",
    "for DATASET_NAME in dataset_names:\n",
    "    print(DATASET_NAME)\n",
    "\n",
    "    sensitive_attrs = datasets[DATASET_NAME]\n",
    "\n",
    "    sensitive_attr = sensitive_attrs[0] # This is only for this expeirment, we don't need\n",
    "                                        #   a list of sensitive attributes since we are focusing\n",
    "                                        #   on RAC1P_Recoded\n",
    "\n",
    "    global_metric_setting = datasets_settings[DATASET_NAME][0]\n",
    "    lambda_list = lambda_settings[DATASET_NAME]\n",
    "\n",
    "    print(f\"Running pipeline for dataset: {DATASET_NAME}\")\n",
    "    if DATASET_NAME in ('ACSEmployment','ACSIncome','ACSMobility','ACSPublicCoverage','ACSTravelTime'):\n",
    "        X = pd.read_csv(f'matrices/{DATASET_NAME}/Xs.csv')\n",
    "        y = pd.read_csv(f'matrices/{DATASET_NAME}/ys.csv').squeeze()\n",
    "    else:\n",
    "        X = pd.read_csv(f'matrices/{DATASET_NAME}/X.csv')\n",
    "        y = pd.read_csv(f'matrices/{DATASET_NAME}/y.csv').squeeze()\n",
    "\n",
    "    X_raw = X.copy()\n",
    "    num_of_groups_list = [  # Sets of groups for which the experiment will run\n",
    "                          [1,2], # White, Black\n",
    "                          [1,2,3], # White, Black, Asian\n",
    "                          [1,2,3,4] # White, Black, Asain, Other\n",
    "                          ]\n",
    "\n",
    "    for groups in num_of_groups_list:\n",
    "        X = X_raw.loc[X_raw[sensitive_attr].isin(groups)]\n",
    "\n",
    "        # remove any rows that have null or nan\n",
    "        X.dropna(inplace=True)\n",
    "        \n",
    "        # Select appropiate y rows\n",
    "        y = y[X.index]\n",
    "\n",
    "    \n",
    "\n",
    "        dataset = FairDataset(X, y, sensitive_attrs)\n",
    "\n",
    "        pipeline = FairPipeline(classifiers=my_classifiers, \n",
    "                                classifier_config_path=classifier_config_path, \n",
    "                                metrics=metrics_dict,\n",
    "                                metric_functions=metrics_functions,\n",
    "                                global_metric=global_metrics_map[global_metric_setting],\n",
    "                                lambdas=lambda_list,\n",
    "                                max_error=0.01, max_total_combinations=50000)\n",
    "\n",
    "        pipeline.tune_and_evaluate(dataset, DATASET_NAME, sensitive_attr)\n",
    "        results = pipeline.results_df\n",
    "        results['sensitive_attr'] = sensitive_attr\n",
    "        results['dataset'] = DATASET_NAME\n",
    "        groups_str = ','.join(str(g) for g in groups)\n",
    "        results['groups_included'] = groups_str\n",
    "        # all_results = all_results.append(results, ignore_index=True)\n",
    "        all_results = pd.concat([all_results, results], ignore_index=True)\n",
    "        print()\n",
    "        print('Overall max_error')\n",
    "        print(pipeline.overall_max_error)\n",
    "        print()\n",
    "\n",
    "        # this avoids memory issues\n",
    "        del X, y, dataset\n",
    "        gc.collect()\n",
    "\n",
    "        print(\"Pipeline run completed.\")\n",
    "\n",
    "        all_results.to_pickle(OUTPUT_FILE)\n",
    "\n",
    "        break\n",
    "    break\n",
    "else:\n",
    "    print(f\"Dataset {DATASET_NAME} not found in the configuration.\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ACSMobility\n",
      "Running pipeline for dataset: ACSMobility\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Following metrics are OVERALL:\n",
      "PRE Train AUC:  0.7000572503859708\n",
      "PRE Test AUC:  0.7038481328025563\n",
      "PRE Calibration Train F1 Score:  0.8712160082093381\n",
      "PRE Calibration Test F1 Score:  0.8828402366863906\n",
      "\n",
      "Overall metrics for xgb (original): {'tpr': 1.0, 'fpr': 1.0, 'precision': 0.7902542372881356, 'npv': 0, 'accuracy': 0.7902542372881356, 'f1': 0.8828402366863906, 'selection_rate': 1.0, 'AUC': 0.7038481328025563}\n",
      "Hyperparameters: {'n_estimators': 10, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 0.1}\n",
      "Metrics for xgb (original) on 1: {'tpr': 1.0, 'fpr': 1.0, 'precision': 0.772020725388601, 'npv': 0, 'accuracy': 0.772020725388601, 'f1': 0.871345029239766, 'selection_rate': 1.0, 'AUC': 0.6794920683343503}\n",
      "Hyperparameters: {'n_estimators': 10, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 0.1}\n",
      "Metrics for xgb (original) on 2: {'tpr': 1.0, 'fpr': 1.0, 'precision': 0.872093023255814, 'npv': 0, 'accuracy': 0.872093023255814, 'f1': 0.9316770186335404, 'selection_rate': 1.0, 'AUC': 0.8418181818181818}\n",
      "Hyperparameters: {'n_estimators': 10, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 0.1}\n",
      "Number of points in the epsilon net: 40\n",
      "Adjusted max_error: 0.01\n",
      "Number of points in data: 472\n",
      "Number of CPU cores available: 8\n",
      "Number of running processes: 561\n",
      "<multiprocessing.context.SpawnContext object at 0x7f87a854cf40>\n",
      "Enters pool\n",
      "Submits futures\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Threshold Combinations: 100%|██████████| 1600/1600 [00:14<00:00, 107.25it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best objective value: 1.7731553769000619\n",
      "Best thresholds: {1: 0.6923076923076923, 2: 0.6666666666666666}\n",
      "Epsilon differences: {1: {2: array([0.0412528 , 0.23863636, 0.12083749, 0.0042735 , 0.02644897])}, 2: {1: array([0.0412528 , 0.23863636, 0.12083749, 0.0042735 , 0.02644897])}}\n",
      "Overall metrics for xgb (fair): {'tpr': 0.8203753351206434, 'fpr': 0.5757575757575758, 'precision': 0.8429752066115702, 'npv': 0.3853211009174312, 'accuracy': 0.7372881355932204, 'f1': 0.8315217391304348, 'selection_rate': 0.7690677966101694, 'AUC': 0.7038481328025563}\n",
      "Hyperparameters: {'n_estimators': 10, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 0.1}\n",
      "Metrics for xgb (fair) on 1: {'tpr': 0.8120805369127517, 'fpr': 0.6022727272727273, 'precision': 0.8203389830508474, 'npv': 0.38461538461538464, 'accuracy': 0.7176165803108808, 'f1': 0.8161888701517707, 'selection_rate': 0.7642487046632125, 'AUC': 0.6794920683343503}\n",
      "Hyperparameters: {'n_estimators': 10, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 0.1}\n",
      "Metrics for xgb (fair) on 2: {'tpr': 0.8533333333333334, 'fpr': 0.36363636363636365, 'precision': 0.9411764705882353, 'npv': 0.3888888888888889, 'accuracy': 0.8255813953488372, 'f1': 0.8951048951048952, 'selection_rate': 0.7906976744186046, 'AUC': 0.8418181818181818}\n",
      "Hyperparameters: {'n_estimators': 10, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 0.1}\n",
      "\n",
      "Overall max_error\n",
      "0.01\n",
      "\n",
      "Pipeline run completed.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "all_results.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>classifier</th>\n",
       "      <th>dataset_subset</th>\n",
       "      <th>method</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>precision</th>\n",
       "      <th>npv</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>...</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>best_objective_value</th>\n",
       "      <th>best_thresholds</th>\n",
       "      <th>best_epsilons</th>\n",
       "      <th>max_epsilon</th>\n",
       "      <th>lambda</th>\n",
       "      <th>global_metric</th>\n",
       "      <th>sensitive_attr</th>\n",
       "      <th>groups_included</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACSMobility</td>\n",
       "      <td>xgb</td>\n",
       "      <td>overall</td>\n",
       "      <td>original</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.790254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790254</td>\n",
       "      <td>0.882840</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RAC1P_recoded</td>\n",
       "      <td>1,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACSMobility</td>\n",
       "      <td>xgb</td>\n",
       "      <td>1</td>\n",
       "      <td>original</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>0.871345</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RAC1P_recoded</td>\n",
       "      <td>1,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACSMobility</td>\n",
       "      <td>xgb</td>\n",
       "      <td>2</td>\n",
       "      <td>original</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.872093</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RAC1P_recoded</td>\n",
       "      <td>1,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACSMobility</td>\n",
       "      <td>xgb</td>\n",
       "      <td>overall</td>\n",
       "      <td>fair</td>\n",
       "      <td>0.820375</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>0.385321</td>\n",
       "      <td>0.737288</td>\n",
       "      <td>0.831522</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.773155</td>\n",
       "      <td>{1: 0.6923076923076923, 2: 0.6666666666666666}</td>\n",
       "      <td>{1: {2: [0.04125279642058166, 0.23863636363636...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>npv</td>\n",
       "      <td>RAC1P_recoded</td>\n",
       "      <td>1,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACSMobility</td>\n",
       "      <td>xgb</td>\n",
       "      <td>1</td>\n",
       "      <td>fair</td>\n",
       "      <td>0.812081</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.820339</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.717617</td>\n",
       "      <td>0.816189</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.773155</td>\n",
       "      <td>{1: 0.6923076923076923, 2: 0.6666666666666666}</td>\n",
       "      <td>{1: {2: [0.04125279642058166, 0.23863636363636...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>npv</td>\n",
       "      <td>RAC1P_recoded</td>\n",
       "      <td>1,2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset classifier dataset_subset    method       tpr       fpr  \\\n",
       "0  ACSMobility        xgb        overall  original  1.000000  1.000000   \n",
       "1  ACSMobility        xgb              1  original  1.000000  1.000000   \n",
       "2  ACSMobility        xgb              2  original  1.000000  1.000000   \n",
       "3  ACSMobility        xgb        overall      fair  0.820375  0.575758   \n",
       "4  ACSMobility        xgb              1      fair  0.812081  0.602273   \n",
       "\n",
       "   precision       npv  accuracy        f1  ...  max_depth  learning_rate  \\\n",
       "0   0.790254  0.000000  0.790254  0.882840  ...          1            0.1   \n",
       "1   0.772021  0.000000  0.772021  0.871345  ...          1            0.1   \n",
       "2   0.872093  0.000000  0.872093  0.931677  ...          1            0.1   \n",
       "3   0.842975  0.385321  0.737288  0.831522  ...          1            0.1   \n",
       "4   0.820339  0.384615  0.717617  0.816189  ...          1            0.1   \n",
       "\n",
       "   best_objective_value                                 best_thresholds  \\\n",
       "0                   NaN                                             NaN   \n",
       "1                   NaN                                             NaN   \n",
       "2                   NaN                                             NaN   \n",
       "3              1.773155  {1: 0.6923076923076923, 2: 0.6666666666666666}   \n",
       "4              1.773155  {1: 0.6923076923076923, 2: 0.6666666666666666}   \n",
       "\n",
       "                                       best_epsilons  max_epsilon  lambda  \\\n",
       "0                                                NaN          NaN     NaN   \n",
       "1                                                NaN          NaN     NaN   \n",
       "2                                                NaN          NaN     NaN   \n",
       "3  {1: {2: [0.04125279642058166, 0.23863636363636...          1.0     2.0   \n",
       "4  {1: {2: [0.04125279642058166, 0.23863636363636...          1.0     2.0   \n",
       "\n",
       "  global_metric sensitive_attr  groups_included  \n",
       "0           NaN  RAC1P_recoded              1,2  \n",
       "1           NaN  RAC1P_recoded              1,2  \n",
       "2           NaN  RAC1P_recoded              1,2  \n",
       "3           npv  RAC1P_recoded              1,2  \n",
       "4           npv  RAC1P_recoded              1,2  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "569d6b7e9215e11aba41c6454007e5c1b78bad7df09dab765d8cf00362c40f03"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}