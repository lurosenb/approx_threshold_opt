{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from math import log10, floor\n",
    "\n",
    "from approx_thresh_general import ApproxThresholdGeneral\n",
    "from approx_thresh import ApproxThreshold\n",
    "from approx_thresh_general import tpr, fpr, precision\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "metrics_functions = {\n",
    "    'tpr': tpr,\n",
    "    'fpr': fpr,\n",
    "    'precision': precision,\n",
    "}\n",
    "\n",
    "from descartes import PolygonPatch\n",
    "from folktables import ACSDataSource, ACSEmployment, ACSIncome, ACSPublicCoverage, ACSMobility, ACSTravelTime\n",
    "import seaborn as sns\n",
    "\n",
    "from shapely.ops import nearest_points\n",
    "from shapely import Polygon\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ACS Datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"NY\"], download=True)\n",
    "\n",
    "folktables = {\n",
    "    \"ACSEmployment\": ACSEmployment,\n",
    "    \"ACSIncome\": ACSIncome,\n",
    "    \"ACSMobility\": ACSMobility,\n",
    "    \"ACSPublicCoverage\": ACSPublicCoverage,\n",
    "    \"ACSTravelTime\": ACSTravelTime\n",
    "}\n",
    "\n",
    "#race_agg_names = {1: 'White',\n",
    "#                  2: 'Black or African American alone',\n",
    "#                  3: 'Asian alone',\n",
    "#                  4: 'Other'}\n",
    "\n",
    "RAC1P_mapper = {1:1,\n",
    "                2:2,\n",
    "                3:4,\n",
    "                4:4,\n",
    "                5:4,\n",
    "                6:3,\n",
    "                7:4,\n",
    "                8:4,\n",
    "                9:4}\n",
    "\n",
    "#SEX_mapper = {1: 1,\n",
    "#              2: 2}\n",
    "\n",
    "#HISP_mapper = {x: 1 if x == 0 else 2 for x in range(0, 24)}\n",
    "\n",
    "# New codes:\n",
    "# 1 - White alone\n",
    "# 2 - Black or African American alone\n",
    "# 3 - Asian alone\n",
    "# 4 - Other\n",
    "\n",
    "for name in list(folktables.keys()):\n",
    "    df = None\n",
    "    \n",
    "    # Add HISP\n",
    "    folktables[name].features.append('HISP')\n",
    "    \n",
    "    features, label, group = folktables[name].df_to_numpy(acs_data)\n",
    "    feature_names = folktables[name].features\n",
    "    df = pd.DataFrame(features, columns = feature_names)\n",
    "    df['RAC1P_recoded'] = df['RAC1P'].map(RAC1P_mapper)\n",
    "    df['label'] = label\n",
    "\n",
    "    outdir = f'matrices/{name}'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.makedirs(outdir)\n",
    "        #os.chmod(outdir,rwx)\n",
    "\n",
    "    # Save full datasets\n",
    "    X = df.drop(columns=['label'])\n",
    "    X.to_csv(f'{outdir}/X.csv',index=False)\n",
    "\n",
    "    y = df['label'].apply(lambda x: 1 if x else 0)\n",
    "    y.to_csv(f'{outdir}/y.csv',index=False)\n",
    "\n",
    "    # Save sample datasets\n",
    "    _ , dfs = train_test_split(df, test_size=0.05,random_state=42)\n",
    "    dfs.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    X = dfs.drop(columns=['label'])\n",
    "    X.to_csv(f'{outdir}/Xs.csv',index=False)\n",
    "\n",
    "    y = dfs['label'].apply(lambda x: 1 if x else 0)\n",
    "    y.to_csv(f'{outdir}/ys.csv',index=False)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Portuguese Students"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "students_df_raw = pd.read_csv('data/students.csv',delimiter=',')\n",
    "students_df = students_df_raw.copy()\n",
    "\n",
    "# Pre-processing: make target, code sex, address, parents education\n",
    "students_df['label'] = students_df['G3'].apply(lambda x: 1 if x < 10 else 0)\n",
    "students_df['sex'] = students_df['sex'].apply(lambda x: 1 if x == 'F' else 0)\n",
    "students_df['address'] = students_df['address'].apply(lambda x: 1 if x == 'R' else 0)\n",
    "\n",
    "# Mapping for Education\n",
    "# 1: Other\n",
    "# 2: High school\n",
    "# 3: University or greater\n",
    "students_df['parents_education'] = students_df.apply(lambda row: max(row.Medu,row.Fedu), axis=1)\n",
    "\n",
    "# From the Portuguese students dataset:\n",
    "# (numeric: 0 - none, 1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education)\n",
    "\n",
    "students_education_recoder = {\n",
    "    0: 0,\n",
    "    1: 0,\n",
    "    2: 0,\n",
    "    3: 1,\n",
    "    4: 2,\n",
    "}\n",
    "\n",
    "students_df['parents_education'] = students_df['parents_education'].map(students_education_recoder)\n",
    "\n",
    "def recode_to_binary(x):\n",
    "    if x == 'yes':\n",
    "        return 1\n",
    "    elif x == 'no':\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "students_df = students_df.applymap(recode_to_binary)\n",
    "\n",
    "one_hot_variables = ['Subject','school','famsize','Pstatus','Mjob','Fjob','reason','guardian']\n",
    "for v in one_hot_variables:\n",
    "    temp = None # This is likely useless, but I have a reason for keeping it... it will remain a mystery to you, the reader of this code\n",
    "    temp = pd.get_dummies(students_df[v])\n",
    "    students_df = pd.merge(students_df,temp.add_suffix(f'_{v}'), how='left',left_index=True, right_index=True)\n",
    "    students_df.drop(columns=[v],inplace=True)\n",
    "\n",
    "students_df.drop(columns=['ID'],inplace=True)\n",
    "\n",
    "outdir = f'matrices/students'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "    #os.chmod(outdir,rwx)\n",
    "\n",
    "X = students_df.drop(columns=['label'])\n",
    "X.to_csv(f'{outdir}/X.csv',index=False)\n",
    "\n",
    "y = students_df['label'].apply(lambda x: 1 if x else 0)\n",
    "y.to_csv(f'{outdir}/y.csv',index=False)\n",
    "\n",
    "X.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tiawenese Loan Assessment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loans_df_raw = pd.read_csv('data/loans.csv',delimiter=',')\n",
    "loans_df = loans_df_raw.copy()\n",
    "loans_df['sex'] = loans_df['SEX'].apply(lambda x: 1 if x == 2 else 0)\n",
    "loans_df.drop(columns=['SEX'],inplace=True)\n",
    "\n",
    "# Mapping for Education\n",
    "# 1: Other\n",
    "# 2: High school\n",
    "# 3: University or greater\n",
    "loans_df['education'] = loans_df['EDUCATION']\n",
    "\n",
    "# From the dataset description:\n",
    "# Education (1 = graduate school; 2 = university; 3 = high school; 4 = others)\n",
    "\n",
    "loans_education_recoder = {\n",
    "    1: 2,\n",
    "    2: 2,\n",
    "    3: 1,\n",
    "    4: 0,\n",
    "}\n",
    "\n",
    "loans_df['education'] = loans_df['education'].map(loans_education_recoder)\n",
    "loans_df['education'] = loans_df['education'].fillna(0)\n",
    "\n",
    "loans_df['label'] = loans_df['default payment next month']\n",
    "\n",
    "outdir = f'matrices/loans'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "    #os.chmod(outdir,rwx)\n",
    "\n",
    "loans_df.drop(columns='ID',inplace=True)\n",
    "\n",
    "X = loans_df.drop(columns=['label'])\n",
    "X.to_csv(f'{outdir}/X.csv',index=False)\n",
    "\n",
    "y = loans_df['label'].apply(lambda x: 1 if x else 0)\n",
    "y.to_csv(f'{outdir}/y.csv',index=False)\n",
    "\n",
    "X.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Diabetes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "diabetes_df_raw = pd.read_csv('data/diabetes.csv',delimiter=',')\n",
    "diabetes_df = diabetes_df_raw.copy()\n",
    "\n",
    "# Pre-processing: make target, code sex, address, parents education\n",
    "diabetes_df['label'] = diabetes_df['class'].apply(lambda x: 1 if x == 'Positive' else 0)\n",
    "diabetes_df.drop(columns=['class'],inplace=True)\n",
    "\n",
    "diabetes_df['SEX'] = diabetes_df['Gender'].apply(lambda x: 1 if x == 'Female' else 0)\n",
    "diabetes_df.drop(columns=['Gender'],inplace=True)\n",
    "\n",
    "def recode_to_binary(x):\n",
    "    if x == 'Yes':\n",
    "        return 1\n",
    "    elif x == 'No':\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "diabetes_df = diabetes_df.applymap(recode_to_binary)\n",
    "\n",
    "outdir = f'matrices/diabetes'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "    #os.chmod(outdir,rwx)\n",
    "\n",
    "X = diabetes_df.drop(columns=['label'])\n",
    "X.to_csv(f'{outdir}/X.csv',index=False)\n",
    "\n",
    "y = diabetes_df['label'].apply(lambda x: 1 if x else 0)\n",
    "y.to_csv(f'{outdir}/y.csv',index=False)\n",
    "\n",
    "X.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Heart Disease"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "heart_disease = fetch_ucirepo(id=45) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "heart_disease_df = heart_disease.data.features \n",
    "heart_disease_df['label'] = heart_disease.data.targets\n",
    "\n",
    "outdir = f'matrices/heart_disease'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "    #os.chmod(outdir,rwx)\n",
    "\n",
    "X = heart_disease_df.drop(columns=['label'])\n",
    "X.to_csv(f'{outdir}/X.csv',index=False)\n",
    "\n",
    "y = heart_disease_df['label'].apply(lambda x: 1 if x else 0)\n",
    "y.to_csv(f'{outdir}/y.csv',index=False)\n",
    "\n",
    "X.head()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "569d6b7e9215e11aba41c6454007e5c1b78bad7df09dab765d8cf00362c40f03"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}